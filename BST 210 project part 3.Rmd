---
title: "Part 3"
author: "Daniel Herrera"
date: "11/23/2021"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(e1071)
library(randomForest)
library(mice)
library(survival)
library(survminer)


bone <- read.csv("data.csv")

# remove HLA_match_raw (was already converted into a different column)
bone <- select(bone, -HLA_match_raw)


# convert numeric columns to numeric
bone_num <- c("donor_age", "recipient_age", "recipient_body_mass", "CD34_x1e6_per_kg...CD34kgx10d6",
           "CD3_x1e8_per_kg", "CD3_to_CD34_ratio", "ANC_recovery", "PLT_recovery",
           "time_to_acute_GvHD_III_IV", "survival_time", "survival_status")

bone[,bone_num] <- lapply(bone_num, function(x) as.numeric(bone[[x]]))
```

We will begin by exploring our missing data for CMV status. This variable is deemed important by our domain experts so we need to explore why there appears to be missingness to decide on the most reasonable steps to handle this missingness. 

```{r}
bone %>%  
  group_by(CMV_status) %>% 
  tally()
```

There are 16 individuals which have missing values for cmv_status. 

We will firt explore the outcomes of the individuals with missing values. 

```{r}
bone %>%
  group_by(CMV_status) %>% 
  summarize( n = n(), survivers = sum(survival_status), deceased = n - survivers, percent_surv = survivers/n)
```

We do see that those who had cmv_status missing had higher percent of survival comparatively, with 62.5% surviving while the next highest cmv_status group was 46.15%.


We can try to explore other variables that may be useful when trying to understand if this difference is meaningful.  

It appears, roughly, that there is some overlap in the percentage of the total that are receive bone marrow as the stem cell source among the missing compared to other groups. Additionally, there appears to be overlap in the missing values compared to other cmv_status levels with respect to recipient body mass. Lastly, there also appears to roughly be a similar proportion of males/females in the missing cmv status group compared to other levels. 


```{r}
# cmv_satus and stem cell source
bone %>%
  group_by(CMV_status) %>% 
  summarize( n = n(), `peripheral blood` = sum(stem_cell_source == "peripheral_blood"), `bone marrow` = sum(stem_cell_source == "bone_marrow"), bm_proportion = `bone marrow`/n)



# cmv_status and recipient body mass

ggplot(data = bone, aes(x = as.factor(CMV_status), y = recipient_body_mass)) + 
  geom_boxplot() +
  xlab(" CMV Status") + 
  ylab("Recipient Body Mass") + 
  theme_classic()

# cmv and gender
bone %>%
  group_by(CMV_status) %>% 
  summarize( n = n(), `male recipient` = sum(recipient_gender == "male"), `female recipient` = sum(recipient_gender == "female"), `male proportion` = `male recipient` / n)



```



#### Naive approach

We will perform several supervised learning techniques using a training and testing split of the complete cases to try to predict survival status effectively.

Note: There are 5 missing cd3 values. This is an important variable so we may have to address this further. For now we will drop these 5 values as well; however, we will try to impute them later using the MICE package. 


```{r}

# attempt at a similar "full model"

predictors <- bone[,c(1:27,37)] # selects only predictors and survival (the outcome)

# make NA the ones with missing CMV status
predictors_CMV <- predictors %>% 
  mutate(CMV_status = na_if(CMV_status, "?"))


#find complete cases only
comp_cases_CMV <- predictors_CMV %>% 
  drop_na()

# use only variables which are not redundant and avoid possibility of multicolinearity
comp_cases_CMV <- comp_cases_CMV %>% 
  select(c(survival_status, recipient_age, recipient_gender, recipient_body_mass,
           recipient_ABO, recipient_rh, recipient_CMV, donor_age, stem_cell_source, disease, gender_match, ABO_match, CMV_status,stem_cell_source, CD34_x1e6_per_kg...CD34kgx10d6, CD3_x1e8_per_kg))
         

# Create test/train data
set.seed(1)
# split test and training data into 50/50
trainIndex <- createDataPartition(comp_cases_CMV$survival_status, p = .7, 
                                  list = FALSE, 
                                  times = 1)
train_set <- comp_cases_CMV[ trainIndex,]
test_set <- comp_cases_CMV[-trainIndex,]
```

Now we can try to recreate our previous approach to modeling using a training/testing split to assess generalizability of our data. All using n = 171. Here we still have some missing values for cd3, which we will need to address later.

We have parsed out some variables due to concerns of collinearity due to variables measuring the same or similar metrics. We remove variables included in recipient and donor that can be summarized by '..._match" variables to remove this redundancy.

Our model here has an accuracy of 61.22%.


```{r}
# attempt at a similar "full model"

logistic_full <- glm(survival_status ~ .,
    family = binomial(), data = train_set)

summary(logistic_full)

# create predictions and calc accuracy


glm_probs <- predict(logistic_full, newdata = test_set, type = "response")
glm_preds <- ifelse(glm_probs > 0.5, 1, 0)

confusionMatrix(data = as.factor(glm_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")

```


Let's try using step selection to see which variables may be more important to include in our supervised learning models.

Forward step and backwards step selection determine that CD3 dosage, recipient RH status, disease type and recipient body mass are most important. We will keep cmv_status as important due to our domain knowledge experts. 

```{r}
library(broom)


mod_basic <- glm(survival_status ~ 1, data=comp_cases_CMV, family = "binomial")
stepModel <- step(mod_basic, direction="forward",
                  scope=(~recipient_age+ recipient_gender+ recipient_body_mass+
           recipient_ABO+ recipient_rh+ recipient_CMV+ donor_age+ stem_cell_source+ disease+ gender_match+ ABO_match+ CMV_status+stem_cell_source+ CD34_x1e6_per_kg...CD34kgx10d6+ CD3_x1e8_per_kg),
                  data=comp_cases_CMV)

tidy(stepModel)

```


```{r}
mod_back <- glm(survival_status ~ recipient_age + recipient_gender+ recipient_body_mass+
           recipient_ABO+ recipient_rh+ recipient_CMV+ donor_age+ stem_cell_source+ disease+ gender_match+ ABO_match+ CMV_status+stem_cell_source+ CD34_x1e6_per_kg...CD34kgx10d6+ CD3_x1e8_per_kg, 
                data = comp_cases_CMV, 
                family = "binomial")

backStepModel <- step(mod_back, 
                      direction = "backward",
                      data = comp_cases_CMV)

tidy(backStepModel)
```






We can now try this approach using only the model variables determined as important by forward and backwards step selection. We get an accuracy of 63.27% using this approach, which is slightly higher than our initial full model. 

```{r}
mod_log <- glm(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg,
               data = train_set,
               family = binomial())
summary(mod_log)



glm_probs <- predict(mod_log, newdata = test_set, type = "response")
glm_preds <- ifelse(glm_probs > 0.5, 1, 0)

confusionMatrix(data = as.factor(glm_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")
```






###### KNN

Now we can try this approach of full and reduced models using k-nearest neighbors, bayes, decision trees and random forests. We will have to drop one value which is missing, denoted as '?' from the recipient RH variable. 

With the full model we have an accuracy of 55.1%, meanwhile with the reduced model we have an accuracy of 65.31%

```{r}
# full model

train_knn <- train_set[-which(train_set$recipient_rh == "?"),]

knn_full <- knn3(survival_status ~., data = train_knn)

knn_probs <- predict(knn_full, newdata = test_set)[,2]
knn_preds <- ifelse(knn_probs > 0.5, 1, 0)

confusionMatrix(data = as.factor(knn_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")
```
```{r}
#reduced model
# remove one ? value row for rh
train_knn <- train_set[-which(train_set$recipient_rh == "?"),]


knn_red <- knn3(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg, data = train_knn)

knn_probs_red <- predict(knn_red, newdata = test_set)[,2]
knn_preds_red <- ifelse(knn_probs_red > 0.5, 1, 0)

confusionMatrix(data = as.factor(knn_preds_red), 
                reference = as.factor(test_set$survival_status),
                positive = "1")

```



###### Naive Bayes

With the reduced model, we obtain an accuracy of 61.22% using the Niave Bayes approach compared to 57.14% with the ful model. 


```{r}
# full model
nb_full <- naiveBayes(survival_status ~ ., data = train_set)
nb_preds <- predict(nb_full, newdata = test_set)


confusionMatrix(data = as.factor(nb_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")

```

```{r}
# reduced model
nb_red <- naiveBayes(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg, data = train_set)
nb_preds <- predict(nb_red, newdata = test_set)


confusionMatrix(data = as.factor(nb_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")

```


###### Decision Tree

We will now use decision trees to make predictions of survival status. 

With our full model, the accuracy of the decision trees is 61.22%, meanwhile our reduced model has an accuracy of 59.18%.

```{r}
# full
fit <- rpart(as.factor(survival_status) ~ ., data = train_set)

# will plot the tree 
rpart.plot(fit, cex = 0.5)

# create new dataframe without survival outcomes
# df <- subset(cases_comp2, select = -c(survival_status))

#make predicitons and cutoffs
mypreds <- predict(fit, test_set)
tree_preds <- ifelse(mypreds[,2] > 0.5, 1, 0)


confusionMatrix(data = as.factor(tree_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")
```

```{r}
fit <- rpart(as.factor(survival_status) ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg, data = train_set)

# will plot the tree 
rpart.plot(fit, cex = 0.5)

# create new dataframe without survival outcomes
# df <- subset(cases_comp2, select = -c(survival_status))

#make predicitons and cutoffs
mypreds <- predict(fit, test_set)
tree_preds <- ifelse(mypreds[,2] > 0.5, 1, 0)


confusionMatrix(data = as.factor(tree_preds), 
                reference = as.factor(test_set$survival_status),
                positive = "1")
```


###### Random Forests

We will use the same training data as the knn which removes the one rh = "?" value. 

Very surprisingly, the random forest model has an accuracy of 59.18% when using the full data; meanwhile, the reduced model has an accuracy of 65.31 %. 

```{r}
#full model
set.seed(1)
fit_bag <- randomForest(as.factor(survival_status) ~ ., ntree = 100, data = train_knn)

forest_pred <- predict(fit, newdata = test_set, type = "class")
confusionMatrix(table(pred = forest_pred, true = test_set$survival_status), positive = "1")
```

```{r}
# reduced model 
set.seed(1)
red_bag <- randomForest(as.factor(survival_status) ~ stem_cell_source + recipient_body_mass + recipient_rh +  disease + CD3_x1e8_per_kg, ntree = 100, data = train_knn)

forest_pred_red <- predict(red_bag, newdata = test_set, type = "class")
confusionMatrix(table(pred = forest_pred_red, true = test_set$survival_status), positive = "1")
```


**In summary, the highest accuracy was attained using the reduced models for K-Nearest Neighbors and for Random Forests at 65.31%.**


###### ROC Curves 

We create ROC Curves using our Naive approach where imputation for missing CMV status is not conducted. 

```{r}

# knn reduced model 
roc_knn <- roc(test_set$survival_status, knn_preds_red)

# random forest model 
roc_rf <- roc(test_set$survival_status, as.numeric(levels(forest_pred_red))[forest_pred_red])


ggroc(list("K-Nearest Neighbors" = roc_knn, "Random Forest" = roc_rf), legacy.axes = T, size = 1.5, alpha = 0.8) +
  theme(legend.title = element_blank()) +
  geom_abline(color = "black", linetype = "dashed", alpha = 0.5) +
  xlab("1- Specificity") +
  ylab("Sensitivity") +
  ggtitle("ROC Curves for Best Models (Naive Approach)") + 
  # add better legend title, guide?
  theme_bw()

auc(roc_knn)
auc(roc_rf)

```




# Redo using reduced and with Imputation 

We will use the predictors dataset, before we removed missing values, and recode "?" to be NA. Then we can use use imputation to get values for CMV_status.

```{r}
predictors_CMV <- predictors %>% 
  mutate(CMV_status = na_if(CMV_status, "?")) %>% 
  mutate(CMV_status = as.factor(CMV_status))


imp <- mice(predictors_CMV, method = "rf", m = 1)
data_imp <- complete(imp)
```


We can recreate our dataset using inputed values for CMV_status
```{r}


#find complete cases only
comp_cases2 <- data_imp %>% 
  drop_na()

# use only variables which are not redundant and avoid possibility of multicolinearity
comp_cases2 <- comp_cases2 %>% 
  select(c(survival_status, recipient_age, recipient_gender, recipient_body_mass,
           recipient_ABO, recipient_rh, recipient_CMV, donor_age, stem_cell_source, disease, gender_match, ABO_match, CMV_status,stem_cell_source, CD34_x1e6_per_kg...CD34kgx10d6, CD3_x1e8_per_kg))
         

# Create test/train data
set.seed(1)
# split test and training data into 50/50
trainIndex <- createDataPartition(comp_cases2$survival_status, p = .7, 
                                  list = FALSE, 
                                  times = 1)
train_set2 <- comp_cases2[ trainIndex,]
test_set2 <- comp_cases2[-trainIndex,]
```

Now, we can retry our two best models from previously (KNN and randomForests) to see what occurs for our accuracy.
We will again have to remove the one case where RH status is "?"

Our accuracy for the KNN full model is 55.26%, reduced model is 57.14%.

Our accuracy for the random Forest full model is 58.93%, reduced model is 55.36%
```{r}
#KNN 
# full
train_knn2 <- train_set2[-which(train_set2$recipient_rh == "?"),]

knn_full2 <- knn3(survival_status ~., data = train_knn2)

knn_probs2 <- predict(knn_full2, newdata = test_set2)[,2]
knn_preds2 <- ifelse(knn_probs2 > 0.5, 1, 0)


confusionMatrix(data = as.factor(knn_preds2), 
                reference = as.factor(test_set2$survival_status),
                positive = "1")




# reduced

knn_red2 <- knn3(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg, data = train_knn2)

knn_probs_red2 <- predict(knn_red2, newdata = test_set2)[,2]
knn_preds_red2 <- ifelse(knn_probs_red2 > 0.5, 1, 0)

confusionMatrix(data = as.factor(knn_preds_red2), 
                reference = as.factor(test_set2$survival_status),
                positive = "1")
```


```{r}
#full model
set.seed(1)

fit_bag <- randomForest(as.factor(survival_status) ~ ., ntree = 100, data = train_knn2)

forest_pred2 <- predict(fit, newdata = test_set2, type = "class")
confusionMatrix(table(pred = forest_pred2, true = test_set2$survival_status))


#reduced model
set.seed(1)
fit_bag2 <- randomForest(as.factor(survival_status) ~ stem_cell_source + recipient_body_mass + recipient_rh + disease + CD3_x1e8_per_kg, ntree = 100, data = train_knn2)

forest_pred_red <- predict(fit_bag2, newdata = test_set2, type = "class")
confusionMatrix(table(pred = forest_pred_red, true = test_set2$survival_status))

```

We can also try to include CMV_status, now that it is imputed, in the reduced model and see how this changes our values for accuracy. We note that it does not help improve our accuracy beyond that of the full model for random Forests (58.93%) but is better than the previous reduced model under imputation. Our knn reduced model accuracy is slightly improved to 58.93% also.

```{r}

#reduced model
# random forests
set.seed(1)
fit_bag_red2 <- randomForest(as.factor(survival_status) ~ stem_cell_source + recipient_body_mass + recipient_rh + disease + CD3_x1e8_per_kg +CMV_status, ntree = 100, data = train_knn2)

forest_pred_red2 <- predict(fit_bag_red2, newdata = test_set2, type = "class")
confusionMatrix(table(pred = forest_pred_red2, true = test_set2$survival_status))
```

```{r}
#knn reduced with cmvstatus added

knn_red3 <- knn3(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease + CD3_x1e8_per_kg + CMV_status, data = train_knn2)

knn_probs_red3 <- predict(knn_red3, newdata = test_set2)[,2]
knn_preds_red3 <- ifelse(knn_probs_red3 > 0.5, 1, 0)

confusionMatrix(data = as.factor(knn_preds_red3), 
                reference = as.factor(test_set2$survival_status),
                positive = "1")
```

In summary, after imputation, the accuracy of our KNN reduced model and our Random Forest reduced model are lwoer than when using the naive approach. 

##### Roc Curves after Imputation

```{r}
# knn reduced model 
roc_knn_imp <- roc(test_set2$survival_status, knn_preds_red3)

# random forest model 
roc_rf_imp <- roc(test_set2$survival_status, as.numeric(levels(forest_pred_red2))[forest_pred_red2])


ggroc(list("K-Nearest Neighbors" = roc_knn_imp, "Random Forest" = roc_rf_imp), legacy.axes = T, size = 2, alpha = 0.8) +
  theme(legend.title = element_blank()) +
  geom_abline(color = "black", linetype = "dashed", alpha = 0.5) +
  xlab("1- Specificity") +
  ylab("Sensitivity") +
  ggtitle("ROC Curves for Best Models (Imputation)") + 
  # add better legend title, guide?
  theme_bw()

auc(roc_knn_imp)
auc(roc_rf_imp)
```



#### Survival Analysis 

Firstly we know that we have a categorical value survival_status (dead = 1, alive = 0), which tracks the status of survival for our patients. We also have a variable survival_time which tracks survival time, including time to death. We do not see any indication of censorship information being tracked, so we will make the assumption that no cases were censored. 

1) We can perform survival analysis with this as our outcome and try to replicate the findings of previous research with respect to important variables, 

2) As well, we can include the variables suggested by lasso regression and domain knowledge to explore any meaningful associations. 

#### 1) Survival Analysis with CD3 and CD34 doses as predictors based on previous research.  

We can fit the model and see the summary below. We see that the predictor CD3 dosage is significant, when both predictor variables are included. CD34 dosage is significant when only CD34 dosage is included. These finding align with the research findings previously mentioned.

The estimated hazard ratio for mortality associated with a one unit higher CD3 dose  compared to those with on unit lower is 0.91621 (95% CI: 0.845, 0.9934), holding all other covariates constant, which indicates on average a 8.4% decrease in mortality. When we explore only the model with CD34 as a predictor, the estimated hazard ratio for mortality associated with a one unit higher CD34 dose compared to those with one unit lower is 0.97131 (95% CI: 0.9454, 0.9979), which indicates on average a 2.9% decrease in mortality. Both of these findings indicate a protective effect against mortality when increasing the dosage of CD3 and CD34. 


```{r}
# compare cd34 and cd3 in survival model 

cox_obj <- Surv(bone$survival_time, bone$survival_status)
cox_mod <- coxph(cox_obj ~ CD34_x1e6_per_kg...CD34kgx10d6 + CD3_x1e8_per_kg, data = bone, ties = "exact")

# provide score and LR test statistic
summary(cox_mod)


# reduced with only cd34
cox_red <- coxph(cox_obj ~ CD34_x1e6_per_kg...CD34kgx10d6, data = bone, ties = "exact")

# provide score and LR test statistic
summary(cox_red)


```

We can now assess if this model is appropriate for the data by analyzing the weighted Schoenfeld residuals. We do not utilize log-log plots here since these predictors are continuous variables, and thus not binary. The weighted Schoenfel dresiduals do not show any indication that the proportional hazards assumption does not hold in this case. 


```{r}

# create plot of schoenfeld resids
wt_sch <- cox.zph(cox_mod)
plot(wt_sch) # maybe see a pattern of decreaseing here over time

# check summary to see if problematic
wt_sch

```




