---
title: 'BST 210 Project: Check-In 2'
author: "Daniel Herrera, Willow Duffell, Lauren Mock"
date: "11/6/2021"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### *Group 4 Members:* 

Daniel Herrera  
Willow Duffell  
Lauren Mock

```{r, warning=FALSE, include=FALSE}
library(tidyverse)
library(caret)

bone <- read.csv("data.csv")

# remove HLA_match_raw (was already converted into a different column)
bone <- select(bone, -HLA_match_raw)

# convert numeric columns to numeric
bone_num <- c("donor_age", "recipient_age", "recipient_body_mass", "CD34_x1e6_per_kg...CD34kgx10d6",
           "CD3_x1e8_per_kg", "CD3_to_CD34_ratio", "ANC_recovery", "PLT_recovery",
           "time_to_acute_GvHD_III_IV", "survival_time", "survival_status")

bone[,bone_num] <- lapply(bone_num, function(x) as.numeric(bone[[x]]))
```


# 1) Logistic regression to predict survival

We want to predict the probability of survival after transplantation, given known covariates that can be measured before transplantation. 

*question: what determines dosage amount? so should we include this as a predictor or not?*

```{r}
# remove variables that are measured after transplantation
predictors <- bone[,c(1:24,37)] # selects only predictors and survival (the outcome)

# logistic model with all covariates
mod_all_vars <- glm(survival_status ~ ., family = binomial(), data = predictors)
summary(mod_all_vars)

p_hats <- mod_all_vars$fitted.values
head(p_hats)



# only predicts 2 values, not sure why...

# regardless, we will definitely need to select some variables that make sense

```


## Variables related to the donor

```{r}
# variables related to the donor
mod_donor <- glm(survival_status ~ donor_age + donor_age_below_35 + donor_ABO + donor_CMV, 
            family = binomial(), data = predictors)

head(mod_donor$fitted.values)
```

We can then decide to remove the variable for donor_age_below_35 because of multicolineary. Including this variable will not allow us to properly "hold other variables constant" since the variable age modifies this variable of age_below_35. 

We see here that our predictors are pretty bad, even on a testing only dataset.

```{r}
mod_donor <- glm(survival_status ~ donor_age + donor_ABO + donor_CMV, 
            family = binomial(), data = predictors)
summary(mod_donor)

prediction <- ifelse(mod_donor$fitted.values > 0.5, 1, 0) 
confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(predictors$survival_status),
                positive = "1")
```
 


## Variables related to the recipient

Here we have to deal with the issue of having missing values for the variable recipient_body_mass.
We elect to remove the variables here since only two values are missing and a sample of 185 should be sufficient. 

We can later choose to explore these cases individually to assess if there was any particular reason that these cases should be explored further. 

Our model here is not great, an accuracy of 64.32%. It does not have a balanced sensitivity versus specificity and is actually better at predicting those among the population with outcome of 1, death. This may be to our benefit though, as we would really like to know, of those who died, how many are we predicting death. 


```{r}
#create subset of data with no missing values, ie remove 2 missing bmi
recip_complete <- predictors %>% 
  select(c(survival_status, recipient_age, recipient_gender, recipient_body_mass,
           recipient_ABO, recipient_rh, recipient_CMV)) %>% 
  drop_na()

mod_recip <- glm(survival_status ~ recipient_age + recipient_gender + recipient_body_mass +
                   recipient_ABO + as.factor(recipient_rh) + as.factor(recipient_CMV), 
            family = binomial(), data = recip_complete)
summary(mod_recip)
prediction <- ifelse(mod_recip$fitted.values > 0.5, 1, 0) 
confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(recip_complete$survival_status),
                positive = "1")


mod_disease <- glm(survival_status ~ disease + disease_group, 
            family = binomial(), data = predictors)
summary(mod_disease)

```

Since disease_group and disease have overlap in the shared malignant level, we will select only one. Here we find an accuracy of 59.36% and no statistically significant predictor variables. 

```{r}
mod_disease <- glm(survival_status ~ disease , 
            family = binomial(), data = predictors)
summary(mod_disease)

prediction <- ifelse(mod_disease$fitted.values > 0.5, 1, 0) 
confusionMatrix(data = as.factor(prediction),
                reference = as.factor(predictors$survival_status),
                positive = "1")
```



## Variables related to the closeness of the match

Per our medical expert, not specifically domain expert, the suggestion is to not include HLA Match AND antigen/allele. In this case we will choose to only choose the variable HLA Match out of 10. 

We see again here that our model is pretty ineffective as detecting survival status with an accuracy of 58.82%. 

```{r}
mod_match <- glm(survival_status ~ gender_match + ABO_match + CMV_status + HLA_match..out.of.10. + 
            antigen + allele,
            family = binomial(), data = predictors)
summary(mod_match)
p_hats <- mod_match$fitted.values
head(p_hats, 30)
mean(p_hats)

# looks like something weird is happening with antigen (very bad predictor of survival)

# when we remove antigen, it looks pretty normal
# we can explore it without antigen or allele
mod_match <- glm(survival_status ~ gender_match + ABO_match + CMV_status + HLA_match..out.of.10.,
            family = binomial(), data = predictors)
summary(mod_match)
prediction <- ifelse(mod_match$fitted.values > 0.5, 1, 0) 
confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(predictors$survival_status),
                positive = "1")

```


## Variables related to stem cell source

Again, we are seeing that are model is not doing to well in terms of accuracy of prediction. However, the model for stem cell source is doing well in terms of sensitivity, unfortunately this is offset by its specificity. 

```{r}
mod_source <- glm(survival_status ~ stem_cell_source, 
            family = binomial(), data = predictors)
summary(mod_source)



prediction <- ifelse(mod_source$fitted.values > 0.5, 1, 0)

confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(predictors$survival_status),
                positive = "1")

```


This all lead me to wonder why our predictions are so subpar. Perhaps we should look at the prevalence of death?

We see that there are a reasonable amount who survived and died indicating there is not a substantial imbalance which we would need to consider. 

```{r}
bone %>% 
  count(survival_status)
```


Below we will try again with a more "full" model now that we have parsed out some variables due to concerns of collinearity due to variables measuring the same or similar metrics. 
We remove variables included in recipient and donor that can be summarized by '..._match" variables.

Our model here has an accuracy of 65.41%


```{r}
# attempt at a similar "full model"

#find complete cases only
cases_comp <- predictors %>% 
  select(c(survival_status, recipient_age, recipient_gender, recipient_body_mass,
           recipient_ABO, recipient_rh, recipient_CMV, donor_age, stem_cell_source, disease, gender_match, ABO_match, CMV_status, stem_cell_source)) %>%
  drop_na()


full_mod <- glm(survival_status ~ donor_age  + stem_cell_source + recipient_age  + recipient_body_mass + as.factor(recipient_rh) + disease + gender_match + ABO_match + CMV_status + stem_cell_source, 
                family = binomial(), 
                data = cases_comp)

summary(full_mod)
prediction <- ifelse(full_mod$fitted.values > 0.5, 1, 0) 
confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(cases_comp$survival_status),
                positive = "1")
```


We can try to use forward selection here: 
```{r}
library(broom)

cases_comp <- cases_comp %>% 
  select(c(survival_status, recipient_age, recipient_body_mass,
           recipient_rh, disease, donor_age, stem_cell_source, disease, gender_match, ABO_match, CMV_status))

mod_basic <- glm(survival_status ~ 1, data=cases_comp, family = "binomial")
stepModel <- step(mod_basic, direction="forward",
                  scope=(~ donor_age  + stem_cell_source + recipient_age  + recipient_body_mass + as.factor(recipient_rh) + disease + gender_match + ABO_match + CMV_status + stem_cell_source),
                  data=cases_comp)

tidy(stepModel)
```

Using forward selection, we are given the following model:

survival_status ~ recipient_body_mass + disease + as.factor(recipient_rh) + stem_cell_source
With an AIC of 239.57



Next, we can try backwards selection:
```{r}
mod_back <- glm(survival_status ~ donor_age  + stem_cell_source + recipient_age  + recipient_body_mass + as.factor(recipient_rh) + disease + gender_match + ABO_match + CMV_status + stem_cell_source, 
                data = cases_comp, 
                family = "binomial")

backStepModel <- step(mod_back, 
                      direction = "backward",
                      data = cases_comp)

tidy(backStepModel)
```

With this model selection method, we are given the following model:

survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease
With an AIC value of 239.57


So, whether we use the forward or backwards selection process, we are given the same model. 


Summary statistics of this model are given below:

Here we see that this model gives an overall accuracy of 66% (getting a little better) with sensitivity of 45.7% and specificity of 82.4%. Still, we are not classifying deaths with a very high success rate (yet!)
```{r}
mod.result <- glm(survival_status ~ stem_cell_source + recipient_body_mass + as.factor(recipient_rh) + disease,
                  data = cases_comp,
                  family = binomial())
summary(mod.result)


prediction <- ifelse(mod.result$fitted.values > 0.45, 1, 0) # Changed the cutoff to get better results for sensitivity, lowers overall accuracy though


confusionMatrix(data = as.factor(prediction), 
                reference = as.factor(cases_comp$survival_status),
                positive = "1")
```


Are biggest issue seems to be our sensitivity, or having our model correctly predict a case of death. Let's see where the max possible sensitivity could be based on our current predictive model based on an ROC curve and the area under the curve.

```{r}
library(pROC)

roc_logit <- roc(cases_comp$survival_status, mod.result$fitted.values)

ggroc(list("Logistic" = roc_logit)) +
  theme(legend.title = element_blank()) +
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color = "black", linetype = "dashed") +
  xlab("Sensitivity") +
  ylab("Specificity") +
  ggtitle("ROC Curve")

auc(roc_logit) # Want this to be >0.7
```













